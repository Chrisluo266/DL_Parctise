{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from simple_cnn_to_mnist import CNN_MNIST_MODEL\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tf_iterator(path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    eyes_mat = np.eye(10)\n",
    "    for record in tf.python_io.tf_record_iterator(path):\n",
    "        ex = tf.train.Example()\n",
    "        ex.ParseFromString(record)\n",
    "        raw = ex.features.feature[\"raw\"].bytes_list.value[0]\n",
    "        label = ex.features.feature[\"label\"].int64_list.value[0]\n",
    "        raw = np.frombuffer(raw,np.float32)\n",
    "        images.append(raw)\n",
    "        labels.append(eyes_mat[label])\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-651b66c30f42>:5: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "train_images,train_labels = read_tf_iterator(\"tfrecords/train.tf\")\n",
    "val_images,val_labels = read_tf_iterator(\"tfrecords/val.tf\")\n",
    "test_images,test_labels = read_tf_iterator(\"tfrecords/test.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "input_x = tf.placeholder(tf.float32,(None,784))\n",
    "reshape_x = tf.reshape(input_x,(-1,28,28,1))\n",
    "input_y = tf.placeholder(tf.float32,(None,10))\n",
    "cnn_model = CNN_MNIST_MODEL(reshape_x,input_y,0.001,0.98,50)\n",
    "prediction = cnn_model.forward()\n",
    "train_op,loss,learning_rate,global_step,accuracy = cnn_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(images,labels,batch_size):\n",
    "    batch_index = 0\n",
    "    total_count = min(len(images),len(labels))\n",
    "    epoch = math.ceil(total_count / batch_size)\n",
    "    while(True):\n",
    "        start_index = batch_index*batch_size\n",
    "        end_index = min((batch_index+1)*batch_size,total_count)\n",
    "        batch_images = images[start_index:end_index]\n",
    "        batch_labels = labels[start_index:end_index]\n",
    "        yield batch_images,batch_labels\n",
    "        batch_index = (batch_index + 1) % epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val[100/3000]: loss=545.0377807617188, learning_rate=0.0009604000370018184, accuracy = 0.9685999751091003, global_step=100\n",
      "Val[200/3000]: loss=340.0621032714844, learning_rate=0.0009223681990988553, accuracy = 0.9800000190734863, global_step=200\n",
      "Val[300/3000]: loss=269.81488037109375, learning_rate=0.0008858424844220281, accuracy = 0.9846000075340271, global_step=300\n",
      "Val[400/3000]: loss=236.34603881835938, learning_rate=0.0008507631719112396, accuracy = 0.9864000082015991, global_step=400\n",
      "Val[500/3000]: loss=209.76968383789062, learning_rate=0.0008170729852281511, accuracy = 0.9878000020980835, global_step=500\n",
      "Val[600/3000]: loss=238.28707885742188, learning_rate=0.0007847169181331992, accuracy = 0.9861999750137329, global_step=600\n",
      "Val[700/3000]: loss=223.6804962158203, learning_rate=0.0007536421762779355, accuracy = 0.9869999885559082, global_step=700\n",
      "Val[800/3000]: loss=217.61764526367188, learning_rate=0.0007237979443743825, accuracy = 0.9882000088691711, global_step=800\n",
      "Val[900/3000]: loss=245.2833251953125, learning_rate=0.0006951355608180165, accuracy = 0.9861999750137329, global_step=900\n",
      "Val[1000/3000]: loss=202.93792724609375, learning_rate=0.0006676082848571241, accuracy = 0.9883999824523926, global_step=1000\n",
      "Val[1100/3000]: loss=219.45960998535156, learning_rate=0.0006411710055544972, accuracy = 0.9887999892234802, global_step=1100\n",
      "Val[1200/3000]: loss=215.38169860839844, learning_rate=0.0006157807074487209, accuracy = 0.9882000088691711, global_step=1200\n",
      "Val[1300/3000]: loss=176.47647094726562, learning_rate=0.000591395772062242, accuracy = 0.9908000230789185, global_step=1300\n",
      "Val[1400/3000]: loss=177.9661102294922, learning_rate=0.0005679765017703176, accuracy = 0.9909999966621399, global_step=1400\n",
      "Val[1500/3000]: loss=176.04310607910156, learning_rate=0.0005454847123473883, accuracy = 0.9914000034332275, global_step=1500\n",
      "Val[1600/3000]: loss=174.74151611328125, learning_rate=0.000523883500136435, accuracy = 0.9911999702453613, global_step=1600\n",
      "Val[1700/3000]: loss=191.05999755859375, learning_rate=0.0005031377077102661, accuracy = 0.9896000027656555, global_step=1700\n",
      "Val[1800/3000]: loss=197.7965850830078, learning_rate=0.00048321348731406033, accuracy = 0.9900000095367432, global_step=1800\n",
      "Val[1900/3000]: loss=191.8988037109375, learning_rate=0.00046407824265770614, accuracy = 0.9911999702453613, global_step=1900\n",
      "Val[2000/3000]: loss=186.9584197998047, learning_rate=0.00044570074533112347, accuracy = 0.9901999831199646, global_step=2000\n",
      "Val[2100/3000]: loss=193.83294677734375, learning_rate=0.0004280510183889419, accuracy = 0.9904000163078308, global_step=2100\n",
      "Val[2200/3000]: loss=186.92747497558594, learning_rate=0.00041110021993517876, accuracy = 0.9901999831199646, global_step=2200\n",
      "Val[2300/3000]: loss=190.94374084472656, learning_rate=0.00039482067222706974, accuracy = 0.9909999966621399, global_step=2300\n",
      "Val[2400/3000]: loss=189.62753295898438, learning_rate=0.00037918577436357737, accuracy = 0.9914000034332275, global_step=2400\n",
      "Val[2500/3000]: loss=200.3514404296875, learning_rate=0.00036417003138922155, accuracy = 0.9909999966621399, global_step=2500\n",
      "Val[2600/3000]: loss=192.41378784179688, learning_rate=0.0003497489378787577, accuracy = 0.9918000102043152, global_step=2600\n",
      "Val[2700/3000]: loss=187.8096923828125, learning_rate=0.00033589889062568545, accuracy = 0.9918000102043152, global_step=2700\n",
      "Val[2800/3000]: loss=186.128173828125, learning_rate=0.00032259730505757034, accuracy = 0.9909999966621399, global_step=2800\n",
      "Val[2900/3000]: loss=192.52159118652344, learning_rate=0.0003098224406130612, accuracy = 0.9914000034332275, global_step=2900\n",
      "Val[3000/3000]: loss=196.34463500976562, learning_rate=0.00029755348805338144, accuracy = 0.9909999966621399, global_step=3000\n",
      "Test[3000/3000]: loss=310.02593994140625, learning_rate=0.00029755348805338144, accuracy = 0.991100013256073, global_step=3000\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 3000\n",
    "train_batch_size = 1024\n",
    "\n",
    "get_batch_itor = get_batch(train_images,train_labels,train_batch_size)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in np.arange(EPOCH):\n",
    "        train_batch_images,train_batch_labels = get_batch_itor.__next__()\n",
    "        sess.run(train_op,feed_dict={input_x:train_batch_images,input_y:train_batch_labels})\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            ls,lr,gs,acc = sess.run([loss,learning_rate,global_step,accuracy],feed_dict={input_x:val_images,input_y:val_labels})\n",
    "            print(\"Val[{}/{}]: loss={}, learning_rate={}, accuracy = {}, global_step={}\".format(epoch+1,EPOCH,ls,lr,acc,gs))\n",
    "    ls,lr,gs,acc = sess.run([loss,learning_rate,global_step,accuracy],feed_dict={input_x:test_images,input_y:test_labels})\n",
    "    print(\"Test[{}/{}]: loss={}, learning_rate={}, accuracy = {}, global_step={}\".format(epoch+1,EPOCH,ls,lr,acc,gs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
