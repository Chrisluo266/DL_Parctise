{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a11908f952e0>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def _batch_normal(self,x,training,epsilon=1e-3, decay=0.99):\n",
    "        size = x.shape.as_list()[1]\n",
    "        scale = tf.Variable(tf.ones((size,))*0.1,trainable=True)\n",
    "        offset = tf.Variable(tf.zeros((size,)),trainable=True)\n",
    "\n",
    "        pop_mean =  tf.Variable(tf.zeros((size,)),trainable=False)\n",
    "        pop_var =  tf.Variable(tf.ones((size,)),trainable=False)\n",
    "        batch_mean, batch_var = tf.nn.moments(x, [0])\n",
    "        train_mean_op = tf.assign(pop_mean, pop_mean*decay+batch_mean*(1-decay))\n",
    "        train_var_op = tf.assign(pop_var, pop_var*decay + batch_var*(1-decay))\n",
    "\n",
    "        def batch_statistics():\n",
    "            with tf.control_dependencies([train_mean_op, train_var_op]):\n",
    "                return tf.nn.batch_normalization(x, batch_mean, batch_var, offset, scale, epsilon)\n",
    "\n",
    "        def population_statistics():\n",
    "            return tf.nn.batch_normalization(x, pop_mean, pop_var, offset, scale, epsilon)\n",
    "\n",
    "        return tf.cond(training, batch_statistics, population_statistics),pop_mean,pop_var\n",
    "    \n",
    "    def __init__(self,l1_batch_normal,l2_batch_normal,x,y,drop_rate,isTrain,name:str):\n",
    "        with tf.name_scope(\"Model_\"+name.replace(' ','_')):\n",
    "            self.name = name\n",
    "            self.learning_rate = tf.Variable(0.001,trainable=False,name=\"learning_rate\")\n",
    "            epsilon = 1e-8\n",
    "            _summary_merge_list = []\n",
    "            with tf.name_scope(\"layer1\"+(\"_BN\" if l1_batch_normal else \"\")):\n",
    "                #784-400-150-10神经网络(BN)\n",
    "                wL1 = tf.Variable(tf.truncated_normal([784,400]))\n",
    "                bL1 = tf.Variable(tf.zeros([400]))\n",
    "                mL1 = tf.matmul(x,wL1) + bL1\n",
    "                if l1_batch_normal:\n",
    "                    batch_normal1,pop_mean,pop_var = self._batch_normal(mL1,isTrain,epsilon)\n",
    "                    _summary_merge_list.append(tf.summary.histogram(\"Mean\",pop_mean))\n",
    "                    _summary_merge_list.append(tf.summary.histogram(\"Var\",pop_var))\n",
    "                    rL1 = tf.nn.sigmoid(batch_normal1) \n",
    "                else:\n",
    "                    rL1 = tf.nn.sigmoid(mL1) \n",
    "                rL1 = tf.nn.dropout(rL1,rate=drop_rate)\n",
    "                \n",
    "            with tf.name_scope(\"layer2\"+(\"_BN\" if l2_batch_normal else \"\")):\n",
    "                wL2 = tf.Variable(tf.truncated_normal([400,150]))\n",
    "                bL2 = tf.Variable(tf.zeros([150]))\n",
    "                mL2 = tf.matmul(rL1,wL2) + bL2\n",
    "                if l2_batch_normal:\n",
    "                    batch_normal2,pop_mean,pop_var = self._batch_normal(mL2,isTrain,epsilon)\n",
    "                    _summary_merge_list.append(tf.summary.histogram(\"Mean\",pop_mean))\n",
    "                    _summary_merge_list.append(tf.summary.histogram(\"Var\",pop_var))\n",
    "                    rL2 = tf.nn.sigmoid(batch_normal2) \n",
    "                else:\n",
    "                    rL2 = tf.nn.sigmoid(mL2) \n",
    "                rL2 = tf.nn.dropout(rL2,rate=drop_rate)\n",
    "            with tf.name_scope(\"output\"):\n",
    "                wL3 = tf.Variable(tf.truncated_normal([150,10]))\n",
    "                bL3 = tf.Variable(tf.zeros([10]))\n",
    "                logits = tf.add(tf.matmul(rL2,wL3),bL3,name=\"logits\")\n",
    "                \n",
    "            self.prediction = tf.nn.softmax(logits,name=\"prediction\")\n",
    "\n",
    "            #代价函数\n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(y,logits),name=\"loss\")\n",
    "\n",
    "            #梯度下降法\n",
    "            self.train = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "            #结果存在一个布尔型列表中。m*1\n",
    "            predictionIndex = tf.argmax(self.prediction,1)\n",
    "            realIndex = tf.argmax(y,1)\n",
    "            correct_prediction = tf.equal(predictionIndex,realIndex)\n",
    "\n",
    "            #update learning_rate\n",
    "            self.update_rate = tf.assign(self.learning_rate,self.learning_rate*0.95,name=\"update_lr\")\n",
    "\n",
    "            #求准确率\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32),name=\"Accuracy\")\n",
    "            #merge summary\n",
    "            self._merge_summary(_summary_merge_list)\n",
    "    def _merge_summary(self,summary_merge_list):\n",
    "        summary_merge_list.append(tf.summary.scalar(\"Loss\",self.loss))\n",
    "        summary_merge_list.append(tf.summary.scalar(\"Accuracy\",self.accuracy))\n",
    "        summary_merge_list.append(tf.summary.scalar(\"LearningRate\",self.learning_rate))\n",
    "        self.summay_merge = tf.summary.merge(summary_merge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "#batch_size\n",
    "batch_size = 128\n",
    "#计算批次\n",
    "n_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784],name=\"input_x\") #28*28=784\n",
    "y = tf.placeholder(tf.float32,[None,10],name=\"label_y\") #28*28=784\n",
    "drop_rate = tf.placeholder_with_default(0.1,None,name=\"drop_rate\")\n",
    "isTrain = tf.placeholder_with_default(False,None,name=\"is_train\")\n",
    "\n",
    "L2_BN_MODEL = \"BN L2\"\n",
    "\n",
    "model = Model(False,True,x,y,drop_rate,isTrain,L2_BN_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debugger is waiting for Session.run() connections...**\n",
    "* tf.Session:\n",
    "```\n",
    "   import tensorflow as tf  \n",
    "   from tensorflow.python import debug as tf_debug \n",
    "   \n",
    "   sess = tf.Session()  \n",
    "   sess = tf_debug.TensorBoardDebugWrapperSession(sess, \"127.0.0.1:6007\")  \n",
    "   sess.run(my_fetches)  \n",
    "```\n",
    " \n",
    "   \n",
    "* Estimator | MonitoredSession:  \n",
    "```\n",
    "   import tensorflow as tf  \n",
    "   from tensorflow.python import debug as tf_debug  \n",
    "\n",
    "   hook = tf_debug.TensorBoardDebugHook(\"127.0.0.1:6007\")  \n",
    "   my_estimator.fit(x=x_data, y=y_data, steps=1000, monitors=[hook])  \n",
    "```\n",
    "\n",
    "  \n",
    "* Keras Model:\n",
    "```\n",
    "   import tensorflow as tf  \n",
    "   from tensorflow.python import debug as tf_debug  \n",
    "   import keras  \n",
    "  \n",
    "   keras.backend.set_session(  \n",
    "      tf_debug.TensorBoardDebugWrapperSession(tf.Session(), \"127.0.0.1:6007\"))  \n",
    "   Define your keras model, called \"model\".  \n",
    "   model.fit(...)  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop = 0, model = BN L2,   test_acc = grpc:// debug URL scheme is not implemented on Windows yet.,   train_acc = grpc:// debug URL scheme is not implemented on Windows yet., learning rate = grpc:// debug URL scheme is not implemented on Windows yet.\n",
      "loop = 10, model = BN L2,   test_acc = grpc:// debug URL scheme is not implemented on Windows yet.,   train_acc = grpc:// debug URL scheme is not implemented on Windows yet., learning rate = grpc:// debug URL scheme is not implemented on Windows yet.\n",
      "loop = 20, model = BN L2,   test_acc = grpc:// debug URL scheme is not implemented on Windows yet.,   train_acc = grpc:// debug URL scheme is not implemented on Windows yet., learning rate = grpc:// debug URL scheme is not implemented on Windows yet.\n"
     ]
    }
   ],
   "source": [
    "##目前windows上grpc有问题，并不能成功连接到tensorboard\n",
    "\n",
    "from tensorflow.python import debug as tf_debug\n",
    "with tf.Session() as sess:\n",
    "    sess = tf_debug.TensorBoardDebugWrapperSession(sess, \"127.0.0.1:6007\",send_traceback_and_source_code =False,log_usage=False)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    with tf.summary.FileWriter(\"./debugger/\",graph=sess.graph,session=sess) as logWriter:\n",
    "        for loop in range(50):\n",
    "            for batch in range(n_batch):\n",
    "                batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "                _ = sess.run(model.train,feed_dict={x:batch_xs,y:batch_ys,drop_rate:0.1,isTrain:True})\n",
    "                #logWriter.add_summary(summary,loop*n_batch+batch) \n",
    "            else:\n",
    "                learningRateValue = sess.run(model.update_rate)\n",
    "                test_acc = sess.run(model.accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels,drop_rate:0,isTrain:False})\n",
    "                train_acc = sess.run(model.accuracy,feed_dict = {x:mnist.train.images,y:mnist.train.labels,drop_rate:0,isTrain:False})\n",
    "                if loop % 10 == 0:\n",
    "                    print(\"loop = {}, model = {},   test_acc = {},   train_acc = {}, learning rate = {}\".format(loop,model.name,test_acc,train_acc,learningRateValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
