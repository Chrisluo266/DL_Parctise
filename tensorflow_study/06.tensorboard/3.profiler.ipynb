{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a11908f952e0>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-dad499f1b288>:10: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 128\n",
    "n_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None,784])\n",
    "labels = tf.placeholder(tf.int32, [None,10])\n",
    "\n",
    "# model\n",
    "hidden1 = tf.layers.dense(inputs, 128, activation=tf.nn.relu, name='hidden-1')\n",
    "hidden2 = tf.layers.dense(hidden1, 32, activation=tf.nn.relu, name='hidden-2')\n",
    "logits = tf.layers.dense(hidden2, 10, activation=None, name='logits')\n",
    "\n",
    "# loss + train_op\n",
    "loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(labels, logits=logits))\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "learning_rate = tf.Variable(0.01,trainable=False,name=\"learing_rate\")\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "prediction_index = tf.argmax(tf.nn.softmax(logits),axis=1)\n",
    "label_index = tf.argmax(labels,axis=1)\n",
    "bools_list = tf.equal(prediction_index,label_index)\n",
    "accuracy = tf.reduce_mean(tf.cast(bools_list,tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_summary = tf.summary.scalar(\"Loss\",loss)\n",
    "accuracy_summary = tf.summary.scalar(\"Accuracy\",accuracy)\n",
    "learning_rate_summary = tf.summary.scalar(\"Learning_rate\",learning_rate)\n",
    "test_text_summary = tf.summary.text(\"Test_text\",tf.convert_to_tensor(\"hello tensorflow\"))\n",
    "summary_merge = tf.summary.merge([loss_summary,accuracy_summary,learning_rate_summary,test_text_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.profiler import model_analyzer\n",
    "from tensorflow.python.profiler import option_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\profiler\\internal\\flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.remove_training_nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31 ops no flops stats due to incomplete shapes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop = 0,  test_acc = 0.8414999842643738,   train_acc = 0.8334909081459045,   test_loss=0.6601693630218506,  train_loss=0.69017094373703\n",
      "loop = 5,  test_acc = 0.9186999797821045,   train_acc = 0.9150182008743286,   test_loss=0.281646192073822,  train_loss=0.29932457208633423\n",
      "loop = 10,  test_acc = 0.9365000128746033,   train_acc = 0.9339818358421326,   test_loss=0.22632412612438202,  train_loss=0.23457294702529907\n",
      "loop = 15,  test_acc = 0.9458000063896179,   train_acc = 0.9449818134307861,   test_loss=0.18923373520374298,  train_loss=0.1941930055618286\n",
      "loop = 20,  test_acc = 0.9520999789237976,   train_acc = 0.9525818228721619,   test_loss=0.1668083667755127,  train_loss=0.1673302948474884\n",
      "loop = 25,  test_acc = 0.9562000036239624,   train_acc = 0.9589272737503052,   test_loss=0.1504470407962799,  train_loss=0.14683011174201965\n",
      "loop = 30,  test_acc = 0.9592000246047974,   train_acc = 0.9631636142730713,   test_loss=0.13751156628131866,  train_loss=0.13136352598667145\n",
      "loop = 35,  test_acc = 0.9611999988555908,   train_acc = 0.967018187046051,   test_loss=0.12733420729637146,  train_loss=0.11781712621450424\n",
      "loop = 40,  test_acc = 0.9646000266075134,   train_acc = 0.9701636433601379,   test_loss=0.11929376423358917,  train_loss=0.10691701620817184\n",
      "loop = 45,  test_acc = 0.9664000272750854,   train_acc = 0.9728727340698242,   test_loss=0.11227720975875854,  train_loss=0.09764803946018219\n",
      "loop = 50,  test_acc = 0.9679999947547913,   train_acc = 0.9749818444252014,   test_loss=0.10687783360481262,  train_loss=0.09008672833442688\n",
      "loop = 55,  test_acc = 0.9696999788284302,   train_acc = 0.9766181707382202,   test_loss=0.10134651511907578,  train_loss=0.08300910890102386\n",
      "loop = 60,  test_acc = 0.9713000059127808,   train_acc = 0.9790545701980591,   test_loss=0.09689084440469742,  train_loss=0.07575472444295883\n",
      "loop = 65,  test_acc = 0.9722999930381775,   train_acc = 0.9801999926567078,   test_loss=0.09357541799545288,  train_loss=0.07067373394966125\n",
      "loop = 70,  test_acc = 0.9724000096321106,   train_acc = 0.9822182059288025,   test_loss=0.09118925034999847,  train_loss=0.06511613726615906\n",
      "loop = 75,  test_acc = 0.9733999967575073,   train_acc = 0.9831818342208862,   test_loss=0.08794963359832764,  train_loss=0.06029830500483513\n",
      "loop = 80,  test_acc = 0.9732999801635742,   train_acc = 0.9844181537628174,   test_loss=0.08559201657772064,  train_loss=0.056354768574237823\n",
      "loop = 85,  test_acc = 0.9739999771118164,   train_acc = 0.986090898513794,   test_loss=0.08542361110448837,  train_loss=0.05282145366072655\n",
      "loop = 90,  test_acc = 0.9746999740600586,   train_acc = 0.9869999885559082,   test_loss=0.0822233036160469,  train_loss=0.04886344075202942\n",
      "loop = 95,  test_acc = 0.9746000170707703,   train_acc = 0.9879636168479919,   test_loss=0.0801284909248352,  train_loss=0.046607982367277145\n"
     ]
    }
   ],
   "source": [
    "run_options = tf.RunOptions(trace_level = tf.RunOptions.FULL_TRACE)\n",
    "run_metadata = tf.RunMetadata()\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "profiler = model_analyzer.Profiler(graph=graph)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(init)\n",
    "    with tf.summary.FileWriter(\"./profiler/\",graph=sess.graph,session=sess) as logWriter:\n",
    "        for loop in range(100):\n",
    "            for batch in range(n_batch):\n",
    "                batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "                _ = sess.run(train_op,feed_dict={inputs:batch_xs,labels:batch_ys})\n",
    "            else:\n",
    "                test_acc,test_loss = sess.run([accuracy,loss],feed_dict = {inputs:mnist.test.images,labels:mnist.test.labels})\n",
    "                train_acc,train_loss,summary = sess.run([accuracy,loss,summary_merge],feed_dict = {inputs:mnist.train.images,labels:mnist.train.labels},options=run_options, run_metadata=run_metadata)\n",
    "                profiler.add_step(step=loop, run_meta=run_metadata)\n",
    "                logWriter.add_summary(summary,loop)\n",
    "                logWriter.add_run_metadata(run_metadata, 'step%d' % loop)\n",
    "                if loop % 5 == 0:\n",
    "                    print(\"loop = {},  test_acc = {},   train_acc = {},   test_loss={},  train_loss={}\".format(loop,test_acc,train_acc,test_loss,train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir ./ (started 5:58:36 ago; pid 1096)\n",
      "  - port 6006: logdir ./profiler/ (started 0:02:49 ago; pid 12920)\n",
      "  - port 6006: logdir ./ (started 6:52:22 ago; pid 1356)\n",
      "  - port 6006: logdir ./ (started 6:22:47 ago; pid 14076)\n",
      "  - port 6006: logdir ./ (started 0:31:49 ago; pid 18648)\n",
      "  - port 6006: logdir ./ (started 5:16:57 ago; pid 19100)\n",
      "  - port 6006: logdir ./ (started 4:40:02 ago; pid 20896)\n",
      "  - port 6006: logdir ./ (started 6:31:03 ago; pid 22100)\n",
      "  - port 6006: logdir ./ (started 6:43:06 ago; pid 224)\n",
      "  - port 6006: logdir ./ (started 6:13:44 ago; pid 2928)\n",
      "  - port 6006: logdir ./ (started 1:53:32 ago; pid 5020)\n",
      "  - port 6006: logdir ./ (started 5:14:18 ago; pid 5936)\n",
      "  - port 6006: logdir ./ (started 6:26:49 ago; pid 6148)\n",
      "  - port 6006: logdir ./ (started 4:38:38 ago; pid 6196)\n",
      "  - port 6006: logdir ./profiler/ (started 0:28:45 ago; pid 6380)\n",
      "  - port 6006: logdir ./ (started 1:29:14 ago; pid 9004)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12920), started 0:02:49 ago. (Use '!kill 12920' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2ad0be4ce80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances\n",
    "#print(dir(notebook.manager))\n",
    "notebook.start(\"--logdir=./profiler/ --host=127.0.0.1 --port=6006\")  #在windows下会卡主一定时间，建议还是在外部使用命令行启动好tensorboard\n",
    "#notebook.display(port=6006, height=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph view显示每一个节点的用时，产生timeline\n",
    "TIME_LINE_JSON_DIR = \"./tmp/\"\n",
    "TIME_LINE_JSON_FILE_NAME = \"timeline.json\"\n",
    "\n",
    "profile_graph_opts_builder = option_builder.ProfileOptionBuilder(\n",
    "  option_builder.ProfileOptionBuilder.time_and_memory())\n",
    "\n",
    "os.makedirs(TIME_LINE_JSON_DIR,exist_ok=True)\n",
    "#输出方式为timeline\n",
    "# 输出文件夹必须存在\n",
    "profile_graph_opts_builder.with_timeline_output(timeline_file=os.path.join(TIME_LINE_JSON_DIR,TIME_LINE_JSON_FILE_NAME))\n",
    "#定义显示sess.Run() 第70步的统计数据\n",
    "profile_graph_opts_builder.with_step(49)\n",
    "\n",
    "#显示视图为graph view\n",
    "profiler.profile_graph(profile_graph_opts_builder.build())\n",
    "pass\n",
    "\n",
    "#使用Chrome浏览器使用chrome://tracing/打开json文件进行观看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计内容为所有trainable Variable Op\n",
    "profile_scope_opt_builder = option_builder.ProfileOptionBuilder(\n",
    "  option_builder.ProfileOptionBuilder.trainable_variables_parameter())\n",
    "\n",
    "#显示的嵌套深度为4\n",
    "profile_scope_opt_builder.with_max_depth(10)\n",
    "#显示字段是params，即参数\n",
    "profile_scope_opt_builder.select(['params'])\n",
    "#根据params数量进行显示结果排序\n",
    "profile_scope_opt_builder.order_by('params')\n",
    "\n",
    "profile_scope_opt_builder.with_file_output(\"./params_count.pf\")\n",
    "##这里将导出结果设置为，导出到文件，默认是导出到stdout,可以在jupyter notebook中查看。\n",
    "\n",
    "#显示视图为scope view\n",
    "profiler.profile_name_scope(profile_scope_opt_builder.build())\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_op_opt_builder = option_builder.ProfileOptionBuilder()\n",
    "\n",
    "#显示字段：op执行时间，使用该op的node的数量。 注意：op的执行时间即所有使用该op的node的执行时间总和。\n",
    "profile_op_opt_builder.select(['micros','occurrence'])\n",
    "#根据op执行时间进行显示结果排序\n",
    "profile_op_opt_builder.order_by('micros')\n",
    "#过滤条件：只显示排名top 5\n",
    "profile_op_opt_builder.with_max_depth(4)\n",
    "\n",
    "#显示视图为op view\n",
    "profiler.profile_operations(profile_op_opt_builder.build())\n",
    "pass\n",
    "##执行之后能够在Jupyter Notebook的程序控制台中看到输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_op_opt_builder = option_builder.ProfileOptionBuilder()\n",
    "\n",
    "#显示字段：op占用内存，使用该op的node的数量。 注意：op的占用内存即所有使用该op的node的占用内存总和。\n",
    "profile_op_opt_builder.select(['bytes','occurrence'])\n",
    "#根据op占用内存进行显示结果排序\n",
    "profile_op_opt_builder.order_by('bytes')\n",
    "#过滤条件：只显示排名最靠前的5个op\n",
    "profile_op_opt_builder.with_max_depth(4)\n",
    "\n",
    "#显示视图为op view\n",
    "profiler.profile_operations(profile_op_opt_builder.build())\n",
    "pass\n",
    "##执行之后能够在Jupyter Notebook的程序控制台中看到输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示视图为code view(代码层面)\n",
    "#profiler.profile_python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
