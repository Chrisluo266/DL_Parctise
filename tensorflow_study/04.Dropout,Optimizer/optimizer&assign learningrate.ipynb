{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a11908f952e0>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "#batch_size\n",
    "batch_size = 128\n",
    "#计算批次\n",
    "n_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "\n",
    "#placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784]) #28*28=784\n",
    "y = tf.placeholder(tf.float32,[None,10]) #28*28=784\n",
    "drop_rate = tf.placeholder_with_default(0.2,None)\n",
    "learning_rate = tf.Variable(0.001,trainable=False)\n",
    "\n",
    "#784-400-150-10神经网络\n",
    "wL1 = tf.Variable(tf.truncated_normal([784,400]))\n",
    "bL1 = tf.Variable(tf.zeros([400]))\n",
    "mL1 = tf.matmul(x,wL1) + bL1\n",
    "rL1 = tf.nn.sigmoid(mL1)\n",
    "rL1 = tf.nn.dropout(rL1,rate=drop_rate)\n",
    "\n",
    "wL2 = tf.Variable(tf.truncated_normal([400,150]))\n",
    "bL2 = tf.Variable(tf.zeros([150]))\n",
    "mL2 = tf.matmul(rL1,wL2) + bL2\n",
    "rL2 = tf.nn.sigmoid(mL2)\n",
    "rL2 = tf.nn.dropout(rL2,rate=drop_rate)\n",
    "\n",
    "wL3 = tf.Variable(tf.truncated_normal([150,10]))\n",
    "bL3 = tf.Variable(tf.zeros([10]))\n",
    "logits = tf.matmul(rL2,wL3) + bL3\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "#代价函数\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(y,logits))\n",
    "\n",
    "#梯度下降法\n",
    "ce_train = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "#结果存在一个布尔型列表中。m*1\n",
    "predictionIndex = tf.argmax(prediction,1)\n",
    "realIndex = tf.argmax(y,1)\n",
    "correct_prediction = tf.equal(predictionIndex,realIndex)\n",
    "\n",
    "#update learning_rate\n",
    "update_rate = tf.assign(learning_rate,learning_rate*0.95)\n",
    "\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop = 0, test_acc = 0.8439000248908997,  train_acc = 0.8361636400222778, learning rate = 0.0009500000160187483\n",
      "loop = 1, test_acc = 0.8927000164985657,  train_acc = 0.8867818117141724, learning rate = 0.0009025000035762787\n",
      "loop = 2, test_acc = 0.9086999893188477,  train_acc = 0.9079272747039795, learning rate = 0.0008573749801144004\n",
      "loop = 3, test_acc = 0.9176999926567078,  train_acc = 0.9218000173568726, learning rate = 0.0008145062020048499\n",
      "loop = 4, test_acc = 0.9244999885559082,  train_acc = 0.9290000200271606, learning rate = 0.000773780862800777\n",
      "loop = 5, test_acc = 0.9297999739646912,  train_acc = 0.9369454383850098, learning rate = 0.0007350918021984398\n",
      "loop = 6, test_acc = 0.9332000017166138,  train_acc = 0.9422545433044434, learning rate = 0.0006983372149989009\n",
      "loop = 7, test_acc = 0.9376999735832214,  train_acc = 0.9472363591194153, learning rate = 0.0006634203600697219\n",
      "loop = 8, test_acc = 0.9416000247001648,  train_acc = 0.952963650226593, learning rate = 0.0006302493275143206\n",
      "loop = 9, test_acc = 0.9435999989509583,  train_acc = 0.9548545479774475, learning rate = 0.0005987368640489876\n",
      "loop = 10, test_acc = 0.9445000290870667,  train_acc = 0.9573454260826111, learning rate = 0.0005688000237569213\n",
      "loop = 11, test_acc = 0.9484000205993652,  train_acc = 0.9605090618133545, learning rate = 0.0005403599934652448\n",
      "loop = 12, test_acc = 0.9487000107765198,  train_acc = 0.9623636603355408, learning rate = 0.0005133419763296843\n",
      "loop = 13, test_acc = 0.9516000151634216,  train_acc = 0.9641818404197693, learning rate = 0.00048767487169243395\n",
      "loop = 14, test_acc = 0.951200008392334,  train_acc = 0.9657272696495056, learning rate = 0.0004632911295630038\n",
      "loop = 15, test_acc = 0.95169997215271,  train_acc = 0.9683272838592529, learning rate = 0.00044012657599523664\n",
      "loop = 16, test_acc = 0.9534000158309937,  train_acc = 0.9699272513389587, learning rate = 0.00041812023846432567\n",
      "loop = 17, test_acc = 0.9537000060081482,  train_acc = 0.9711818099021912, learning rate = 0.00039721422945149243\n",
      "loop = 18, test_acc = 0.9553999900817871,  train_acc = 0.972527265548706, learning rate = 0.00037735351361334324\n",
      "loop = 19, test_acc = 0.9567000269889832,  train_acc = 0.973872721195221, learning rate = 0.0003584858204703778\n",
      "loop = 20, test_acc = 0.957099974155426,  train_acc = 0.9750182032585144, learning rate = 0.0003405615279916674\n",
      "loop = 21, test_acc = 0.9581999778747559,  train_acc = 0.9756181836128235, learning rate = 0.00032353345886804163\n",
      "loop = 22, test_acc = 0.9574000239372253,  train_acc = 0.9761090874671936, learning rate = 0.00030735679320059717\n",
      "loop = 23, test_acc = 0.9589999914169312,  train_acc = 0.9772363901138306, learning rate = 0.0002919889520853758\n",
      "loop = 24, test_acc = 0.9584000110626221,  train_acc = 0.9780545234680176, learning rate = 0.0002773895103018731\n",
      "loop = 25, test_acc = 0.9573000073432922,  train_acc = 0.9784363508224487, learning rate = 0.00026352002169005573\n",
      "loop = 26, test_acc = 0.9589999914169312,  train_acc = 0.9789999723434448, learning rate = 0.0002503440191503614\n",
      "loop = 27, test_acc = 0.9599000215530396,  train_acc = 0.9795272946357727, learning rate = 0.00023782681091688573\n",
      "loop = 28, test_acc = 0.9603000283241272,  train_acc = 0.9801636338233948, learning rate = 0.00022593546600546688\n",
      "loop = 29, test_acc = 0.9602000117301941,  train_acc = 0.9806908965110779, learning rate = 0.00021463868324644864\n",
      "loop = 30, test_acc = 0.9603999853134155,  train_acc = 0.9814909100532532, learning rate = 0.00020390674762893468\n",
      "loop = 31, test_acc = 0.9598000049591064,  train_acc = 0.9817090630531311, learning rate = 0.00019371141388546675\n",
      "loop = 32, test_acc = 0.9610000252723694,  train_acc = 0.9819454550743103, learning rate = 0.00018402583373244852\n",
      "loop = 33, test_acc = 0.961899995803833,  train_acc = 0.9824545383453369, learning rate = 0.00017482454131823033\n",
      "loop = 34, test_acc = 0.9605000019073486,  train_acc = 0.9828363656997681, learning rate = 0.00016608330770395696\n",
      "loop = 35, test_acc = 0.9617000222206116,  train_acc = 0.9836727380752563, learning rate = 0.0001577791408635676\n",
      "loop = 36, test_acc = 0.9613999724388123,  train_acc = 0.9838545322418213, learning rate = 0.0001498901838203892\n",
      "loop = 37, test_acc = 0.9621999859809875,  train_acc = 0.9842727184295654, learning rate = 0.00014239567099139094\n",
      "loop = 38, test_acc = 0.9613000154495239,  train_acc = 0.984109103679657, learning rate = 0.00013527588453143835\n",
      "loop = 39, test_acc = 0.9623000025749207,  train_acc = 0.9844181537628174, learning rate = 0.0001285120815737173\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for loop in range(40):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(ce_train,feed_dict={x:batch_xs,y:batch_ys,drop_rate:0.1})\n",
    "        else: \n",
    "            learningRateValue = sess.run(update_rate)\n",
    "            test_acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels,drop_rate:0})\n",
    "            train_acc = sess.run(accuracy,feed_dict = {x:mnist.train.images,y:mnist.train.labels,drop_rate:0})\n",
    "            print(\"loop = {0}, test_acc = {1},  train_acc = {2}, learning rate = {3}\".format(loop,test_acc,train_acc,learningRateValue))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
